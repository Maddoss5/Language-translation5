{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd548961-cde7-42c2-bd94-218e782501c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertTokenizer\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3052504d-5151-4174-b090-bf1105697b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"test.json\",\"r\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8097871-3421-477b-b6d6-601978105e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9eee845-b27b-4014-be1f-e5a1a7faa805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '190315_E001_13',\n",
       " 'tag': 'meeting',\n",
       " 'title': 'Meeting: Market update meeting',\n",
       " 'original_language': 'en',\n",
       " 'conversation': [{'no': 1,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'How is it going, Wayne?',\n",
       "   'ja_sentence': 'ウェイン、調子はどうです？'},\n",
       "  {'no': 2,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': \"I'm not too bad.\",\n",
       "   'ja_sentence': 'まあまあです。'},\n",
       "  {'no': 3,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Thank you very much for coming out today.',\n",
       "   'ja_sentence': '今日はご足労ありがとう。'},\n",
       "  {'no': 4,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': \"How's business lately?\",\n",
       "   'ja_sentence': '景気はどうです？'},\n",
       "  {'no': 5,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': \"It's been good.\",\n",
       "   'ja_sentence': 'おかげさまで、順調です。'},\n",
       "  {'no': 6,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': \"We recently commissioned a new facility so I've been busy managing that.\",\n",
       "   'ja_sentence': '最近、新しい施設が稼働開始しまして、その管理で忙しくて。'},\n",
       "  {'no': 7,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'I read about that on your company website.',\n",
       "   'ja_sentence': 'ああ、それ、御社のサイトで読みましたよ。'},\n",
       "  {'no': 8,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Congratulations.',\n",
       "   'ja_sentence': 'おめでとうございます。'},\n",
       "  {'no': 9,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Thank you.',\n",
       "   'ja_sentence': 'どうも。'},\n",
       "  {'no': 10,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'The Japanese market has been very interested in our product.',\n",
       "   'ja_sentence': '日本市場が当社製品に興味をもっているようです。'},\n",
       "  {'no': 11,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'So having this new facility should satisfy their demand for the next couple of years.',\n",
       "   'ja_sentence': '新施設のおかげで、今後数年間の需要は賄えるかと思います。'},\n",
       "  {'no': 12,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'The Japanese market is trending upwards lately.',\n",
       "   'ja_sentence': '日本市場は最近上向きだね。'},\n",
       "  {'no': 13,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'I was in Japan last month and talked to a couple of potential customers.',\n",
       "   'ja_sentence': '先月日本に出張して、見込みのありそうな数社とミーティングしてきました。'},\n",
       "  {'no': 14,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'They all told me that they are looking for a reliable and consistent supply.',\n",
       "   'ja_sentence': '全社、声を揃えて、信頼できて一貫性のある供給を望んでいましたね。'},\n",
       "  {'no': 15,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Well, we are well positioned then.',\n",
       "   'ja_sentence': 'では、当社はいい状況にあるってわけですね。'},\n",
       "  {'no': 16,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'We have 6 facilities with over 1 million ton capacity.',\n",
       "   'ja_sentence': '出力百万トン以上の工場が6件ありますし。'},\n",
       "  {'no': 17,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'You also operate your own terminal.',\n",
       "   'ja_sentence': '端末も独自に管理されてますしね。'},\n",
       "  {'no': 18,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Yes, so we can control the ship loading and schedule.',\n",
       "   'ja_sentence': 'そう、出荷量やスケジュールも管理できます。'},\n",
       "  {'no': 19,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Having control over the supply chain is definitely helpful.',\n",
       "   'ja_sentence': 'サプライチェーンを管理できるのはとても助かります。'},\n",
       "  {'no': 20,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Being flexible is really important.',\n",
       "   'ja_sentence': '柔軟性があるのはとても重要です。'},\n",
       "  {'no': 21,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'How has the Korean market been lately?',\n",
       "   'ja_sentence': '韓国市場は最近どんな状況ですか？'},\n",
       "  {'no': 22,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': \"I hear that they aren't looking for long term contracts.\",\n",
       "   'ja_sentence': '長期の契約は望んでいないと聞きましたが。'},\n",
       "  {'no': 23,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Is that true?',\n",
       "   'ja_sentence': 'そうなんでしょうか？'},\n",
       "  {'no': 24,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Yes it is.',\n",
       "   'ja_sentence': '本当みたいです。'},\n",
       "  {'no': 25,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'They are mainly looking for spot contract.',\n",
       "   'ja_sentence': '現物契約中心のようです。'},\n",
       "  {'no': 26,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Why is that?',\n",
       "   'ja_sentence': 'どうしてなんでしょう？'},\n",
       "  {'no': 27,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': \"Well they don't want to overcommit to one supplier.\",\n",
       "   'ja_sentence': 'サプライヤー一社に傾倒したくないんでしょうね。'},\n",
       "  {'no': 28,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'So they prefer to source from various suppliers.',\n",
       "   'ja_sentence': 'なので、いろいろなところから調達したいんですよ。'},\n",
       "  {'no': 29,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Is that to also keep the price down?',\n",
       "   'ja_sentence': '価格を抑える意味もあるんでしょうか？'},\n",
       "  {'no': 30,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'They can compare prices and shop around for the cheapest price.',\n",
       "   'ja_sentence': '価格を比較して、一番安いところから購入するのです。'},\n",
       "  {'no': 31,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Sounds like a lot of work.',\n",
       "   'ja_sentence': 'よっぽど、大変そうですがね。'},\n",
       "  {'no': 32,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'We could offer them a 10-year contract and they can sit back and relax.',\n",
       "   'ja_sentence': '10年契約をオファーすれば、向こうはのんびりリラックスできるのに。'},\n",
       "  {'no': 33,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Yeah, that would make life easier.',\n",
       "   'ja_sentence': 'その方が楽でしょうに。'},\n",
       "  {'no': 34,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'We should keep an eye on that market.',\n",
       "   'ja_sentence': '韓国市場からは目が離せないですね。'},\n",
       "  {'no': 35,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Yeah, there is a lot of changes happening lately.',\n",
       "   'ja_sentence': 'そう、最近、いろいろ変化が起きていますからね。'},\n",
       "  {'no': 36,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'We should catch up again in a couple months?',\n",
       "   'ja_sentence': '２ヶ月後くらいにまた、情報交換しましょう。'},\n",
       "  {'no': 37,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'That would be good.',\n",
       "   'ja_sentence': 'いいですね。'},\n",
       "  {'no': 38,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Great.',\n",
       "   'ja_sentence': '良かった。'},\n",
       "  {'no': 39,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Thank you for your time today.',\n",
       "   'ja_sentence': '今日はお時間をありがとうございました。'},\n",
       "  {'no': 40,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Thank you as well.',\n",
       "   'ja_sentence': 'こちらこそ。'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac905ad3-e445-4bba-8b8a-472c76c354c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "english=[]\n",
    "japanese=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd21f0cb-be3c-47c9-9eb0-460b5adef114",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dat in data:\n",
    "    for j in dat['conversation']:\n",
    "        english.append(j['en_sentence'])\n",
    "        japanese.append(j['ja_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50013e7-0cf1-462c-abc6-f16eccc2235c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1e8612-ef7a-4852-8300-1f479e35c64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(japanese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d537196-2d07-48bd-bd2c-9a65e3a049cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_eng=0\n",
    "mx_jp=0\n",
    "for i in range(len(english)):\n",
    "    mx_eng=max(mx_eng,len(english[i]))\n",
    "for i in range(len(japanese)):\n",
    "    mx_jp=max(mx_jp,len(japanese[i]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09703c-0545-4f5a-b1ce-1e0a77f4b9ae",
   "metadata": {},
   "source": [
    "Max of english and Max of Japanese tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61934533-df74-495b-9037-49536ca19c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 95\n"
     ]
    }
   ],
   "source": [
    "print(mx_eng,mx_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44cd-a876-48e0-aa22-b97607712c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a9e297-01b3-422c-aed3-d55a3fd89c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "bertjapanese = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82cfecef-5686-4af6-bd60-7580856cfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    \"bos_token\": \"<sos>\",\n",
    "    \"eos_token\": \"<eos>\",\n",
    "    \"pad_token\": \"<pad>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bbb6e46-f170-4be7-8bfe-be241bd0e8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f012e8fd-06b9-45f7-a232-cab40e3faec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jptokids=[]\n",
    "jptorch=[]\n",
    "for i in range(len(japanese)):\n",
    "    ax = tokenizer.tokenize(japanese[i])\n",
    "    ax = [tokenizer.bos_token] + ax + [tokenizer.eos_token]  \n",
    "    jptokids.append(tokenizer.convert_tokens_to_ids(ax))\n",
    "    jptorch.append(torch.tensor(jptokids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bcdb36-b3c6-4dfb-b9d7-bb612b8594e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fb22e53-41df-4ef0-b7d7-dbb1f59c0c99",
   "metadata": {},
   "source": [
    "This is using tokenizer.encode to automatically add eos and sos \n",
    "\n",
    "for i in range(len(japanese)):\n",
    "    jptokids.append(tokenizer.encode(japanese[i], add_special_tokens=True))  \n",
    "    print(jptokids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fba07688-66ed-4cbe-8e6e-406442b50b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c633c9-41dd-4421-b052-c10bc4288998",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_jp=0\n",
    "vocabsize_jp=0\n",
    "for i in range(len(jptokids)):\n",
    "    maxlen_jp=max(maxlen_jp,len(jptokids[i]))\n",
    "    vocabsize_jp = max(vocabsize_jp,max(jptokids[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f412545b-77cf-490b-974e-270ca3dcc762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 32001)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen_jp,vocabsize_jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3141c88b-b634-4ff8-9658-e725d09479e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engtokenizer=BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5d8a15b-1ffb-44f6-bf9e-9b828c0596e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engtokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1562fb92-99e4-452f-888e-3bcd96083864",
   "metadata": {},
   "outputs": [],
   "source": [
    "engtokids=[]\n",
    "engtorch=[]\n",
    "for i in range(len(english)):\n",
    "    ax=engtokenizer.tokenize(english[i])\n",
    "    ax=[engtokenizer.bos_token]+ax+[engtokenizer.eos_token]\n",
    "    engtokids.append(engtokenizer.convert_tokens_to_ids(ax))\n",
    "    engtorch.append(torch.tensor(engtokids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72bee0a8-d868-4c26-b3c9-e19fcafa76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_eng=0\n",
    "vocabsize_eng=0\n",
    "for i in range(len(engtokids)):\n",
    "    maxlen_eng=max(maxlen_eng,len(engtokids[i]))\n",
    "    vocabsize_eng = max(vocabsize_eng,max(engtokids[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "993addb7-2629-4bd6-a678-bc8b2009308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 30523, 59, 32001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen_eng,vocabsize_eng,maxlen_jp,vocabsize_jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d73fda59-747c-4592-8743-aa05928fad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> ウェイン 、 調子 は どう です ? <eos>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(jptokids[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18b4eb58-0c15-4998-bf7a-d8030eb3a34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how is it going, wayne?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engtokenizer.decode(engtokids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d462bd63-bdb3-4cd9-b6a1-ad0ee9b1fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engpadded= pad_sequence(engtorch, batch_first=True, padding_value=engtokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d8d9227-d8c6-4756-95ee-712e7f0b56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jppadded= pad_sequence(jptorch,batch_first=True ,padding_value=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1de242f9-8acd-4daa-83f8-aadd9ba848df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, en_tensors, jp_tensors):\n",
    "        self.en_tensors = en_tensors\n",
    "        self.jp_tensors = jp_tensors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.en_tensors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return English and Japanese tensors for each sentence pair\n",
    "        return self.en_tensors[idx], self.jp_tensors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ed2b937-b89c-4629-bd11-9e5d2b90bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(en_tensors, jp_tensors, batch_size=32):\n",
    "    dataset = TranslationDataset(en_tensors, jp_tensors)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b641f289-cbec-4d4c-a6d3-af0bcfdc9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_dataloader(engpadded, jppadded, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d5d3c0-fc2c-4164-8452-99e6bfa3ca12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0ca2579-16ec-495a-8c03-8490debb0668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30522,  2017,  1005,  ..., 30524, 30524, 30524],\n",
      "        [30522,  2003,  2008,  ..., 30524, 30524, 30524],\n",
      "        [30522,  3100,  1010,  ..., 30524, 30524, 30524],\n",
      "        ...,\n",
      "        [30522,  5580,  2000,  ..., 30524, 30524, 30524],\n",
      "        [30522,  2339,  2123,  ..., 30524, 30524, 30524],\n",
      "        [30522,  2053,  3291,  ..., 30524, 30524, 30524]])\n",
      "tensor([[32000,    59,   939,  ..., 32002, 32002, 32002],\n",
      "        [32000,  1778,    18,  ..., 32002, 32002, 32002],\n",
      "        [32000, 16015,     6,  ..., 32002, 32002, 32002],\n",
      "        ...,\n",
      "        [32000,   218,     9,  ..., 32002, 32002, 32002],\n",
      "        [32000,  9560,   174,  ..., 32002, 32002, 32002],\n",
      "        [32000,   749,    80,  ..., 32002, 32002, 32002]])\n"
     ]
    }
   ],
   "source": [
    "for i in next(iter(train_loader)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "120b1adc-2626-455f-8a91-63ccf7ff4b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45])\n",
      "torch.Size([59])\n"
     ]
    }
   ],
   "source": [
    "for i in next(iter(train_loader)):\n",
    "    print(i[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e06aaf3-0d42-4c0b-aa48-e4c4d719616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eencoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell  # Return both hidden and cell states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "449c7fae-58ba-48df-b287-ce86237d5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deecoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e63d335c-4a47-4633-b7dd-4ab5ef0e9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "\n",
    "    def forward(self, source_sequence, target_sequence, teacher_forcing_ratio=0.5):\n",
    "        batch_size = target_sequence.shape[0]\n",
    "        target_sequence_length = target_sequence.shape[1]\n",
    "        target_vocabulary_size = self.decoder.output_dim\n",
    "\n",
    "        decoder_outputs = torch.zeros(batch_size, target_sequence_length, target_vocabulary_size)\n",
    "\n",
    "        encoder_hidden, encoder_cell = self.encoder(source_sequence)\n",
    "\n",
    "        decoder_input = target_sequence[:, 0]\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell = encoder_cell\n",
    "\n",
    "        for time_step in range(1, target_sequence_length):\n",
    "            decoder_prediction, decoder_hidden, decoder_cell = self.decoder(decoder_input, decoder_hidden, decoder_cell)\n",
    "            decoder_outputs[:, time_step] = decoder_prediction\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            decoder_input = target_sequence[:, time_step] if teacher_force else decoder_prediction.argmax(1)\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c8a739d-aedb-4820-9470-c0687a89e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "engenc=eencoder(input_dim=31000,emb_dim=30,hid_dim=800,dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e3205a4-fe60-4e75-a19f-976b852c2362",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpdec=deecoder(output_dim=32100,emb_dim=30,hid_dim=800,dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "684f944b-2154-446e-b2a5-fe1524ee39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(engenc, jpdec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7053885-3c13-4578-b041-d36bb66c02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a7b97e6-be5e-4626-bbd3-94db22b1274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, src, trg, optimizer, criterion, clip):\n",
    "    \"\"\"\n",
    "    Trains the model for a single batch.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The sequence-to-sequence model.\n",
    "        src (torch.Tensor): The source sequence batch.\n",
    "        trg (torch.Tensor): The target sequence batch.\n",
    "        optimizer (optim.Optimizer): The optimizer.\n",
    "        criterion (nn.Module): The loss function.\n",
    "        clip (float): The gradient clipping value.\n",
    "        device (torch.device): The device to use (CPU or CUDA).\n",
    "\n",
    "    Returns:\n",
    "        float: The loss for the batch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    output = model(src, trg)\n",
    "\n",
    "    output_dim = output.shape[-1]\n",
    "\n",
    "    output = output[:, 1:].reshape(-1, output_dim)\n",
    "    trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "    loss = criterion(output, trg)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "CLIP=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed6d3dbd-8d24-4c71-b40c-d8af4b8f6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e544567e-468d-452a-bd75-52b7ee81aafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: 10.373\n",
      "Epoch: 01 | Train Loss: 10.336\n",
      "Epoch: 01 | Train Loss: 10.181\n",
      "Epoch: 01 | Train Loss: 8.639\n",
      "Epoch: 01 | Train Loss: 7.724\n",
      "Epoch: 01 | Train Loss: 7.002\n",
      "Epoch: 01 | Train Loss: 6.398\n",
      "Epoch: 01 | Train Loss: 6.703\n",
      "Epoch: 01 | Train Loss: 6.554\n",
      "Epoch: 01 | Train Loss: 6.386\n",
      "Epoch: 01 | Train Loss: 6.436\n",
      "Epoch: 01 | Train Loss: 6.292\n",
      "Epoch: 01 | Train Loss: 6.658\n",
      "Epoch: 01 | Train Loss: 6.597\n",
      "Epoch: 01 | Train Loss: 6.619\n",
      "Epoch: 01 | Train Loss: 6.497\n",
      "Epoch: 01 | Train Loss: 6.181\n",
      "Epoch: 01 | Train Loss: 6.764\n",
      "Epoch: 01 | Train Loss: 6.414\n",
      "Epoch: 01 | Train Loss: 6.222\n",
      "Epoch: 01 | Train Loss: 6.645\n",
      "Epoch: 01 | Train Loss: 6.278\n",
      "Epoch: 01 | Train Loss: 6.234\n",
      "Epoch: 01 | Train Loss: 6.300\n",
      "Epoch: 01 | Train Loss: 6.399\n",
      "Epoch: 01 | Train Loss: 6.245\n",
      "Epoch: 01 | Train Loss: 6.294\n",
      "Epoch: 01 | Train Loss: 6.397\n",
      "Epoch: 01 | Train Loss: 6.225\n",
      "Epoch: 01 | Train Loss: 6.112\n",
      "Epoch: 01 | Train Loss: 6.399\n",
      "Epoch: 01 | Train Loss: 6.423\n",
      "Epoch: 01 | Train Loss: 6.396\n",
      "Epoch: 01 | Train Loss: 6.280\n",
      "Epoch: 01 | Train Loss: 6.131\n",
      "Epoch: 01 | Train Loss: 6.375\n",
      "Epoch: 01 | Train Loss: 6.633\n",
      "Epoch: 01 | Train Loss: 6.303\n",
      "Epoch: 01 | Train Loss: 6.008\n",
      "Epoch: 01 | Train Loss: 5.992\n",
      "Epoch: 01 | Train Loss: 6.281\n",
      "Epoch: 01 | Train Loss: 6.192\n",
      "Epoch: 01 | Train Loss: 6.358\n",
      "Epoch: 01 | Train Loss: 6.377\n",
      "Epoch: 01 | Train Loss: 5.953\n",
      "Epoch: 01 | Train Loss: 6.080\n",
      "Epoch: 01 | Train Loss: 5.962\n",
      "Epoch: 01 | Train Loss: 6.281\n",
      "Epoch: 01 | Train Loss: 6.066\n",
      "Epoch: 01 | Train Loss: 6.234\n",
      "Epoch: 01 | Train Loss: 5.988\n",
      "Epoch: 01 | Train Loss: 6.297\n",
      "Epoch: 01 | Train Loss: 6.137\n",
      "Epoch: 01 | Train Loss: 6.204\n",
      "Epoch: 01 | Train Loss: 6.012\n",
      "Epoch: 01 | Train Loss: 6.225\n",
      "Epoch: 01 | Train Loss: 6.126\n",
      "Epoch: 01 | Train Loss: 5.864\n",
      "Epoch: 01 | Train Loss: 6.090\n",
      "Epoch: 01 | Train Loss: 6.003\n",
      "Epoch: 01 | Train Loss: 6.180\n",
      "Epoch: 01 | Train Loss: 5.996\n",
      "Epoch: 01 | Train Loss: 6.494\n",
      "Epoch: 01 | Train Loss: 5.785\n",
      "Epoch: 01 | Train Loss: 6.105\n",
      "Epoch: 01 | Train Loss: 6.094\n",
      "Epoch: 01 | Train Loss: 6.069\n",
      "Epoch: 02 | Train Loss: 5.695\n",
      "Epoch: 02 | Train Loss: 5.653\n",
      "Epoch: 02 | Train Loss: 5.715\n",
      "Epoch: 02 | Train Loss: 5.647\n",
      "Epoch: 02 | Train Loss: 5.876\n",
      "Epoch: 02 | Train Loss: 5.603\n",
      "Epoch: 02 | Train Loss: 5.763\n",
      "Epoch: 02 | Train Loss: 5.912\n",
      "Epoch: 02 | Train Loss: 5.835\n",
      "Epoch: 02 | Train Loss: 5.713\n",
      "Epoch: 02 | Train Loss: 5.747\n",
      "Epoch: 02 | Train Loss: 5.818\n",
      "Epoch: 02 | Train Loss: 5.592\n",
      "Epoch: 02 | Train Loss: 5.784\n",
      "Epoch: 02 | Train Loss: 5.860\n",
      "Epoch: 02 | Train Loss: 5.740\n",
      "Epoch: 02 | Train Loss: 5.685\n",
      "Epoch: 02 | Train Loss: 5.786\n",
      "Epoch: 02 | Train Loss: 5.790\n",
      "Epoch: 02 | Train Loss: 5.858\n",
      "Epoch: 02 | Train Loss: 5.753\n",
      "Epoch: 02 | Train Loss: 5.845\n",
      "Epoch: 02 | Train Loss: 6.074\n",
      "Epoch: 02 | Train Loss: 5.446\n",
      "Epoch: 02 | Train Loss: 5.983\n",
      "Epoch: 02 | Train Loss: 5.834\n",
      "Epoch: 02 | Train Loss: 5.756\n",
      "Epoch: 02 | Train Loss: 5.711\n",
      "Epoch: 02 | Train Loss: 5.754\n",
      "Epoch: 02 | Train Loss: 5.819\n",
      "Epoch: 02 | Train Loss: 5.978\n",
      "Epoch: 02 | Train Loss: 5.546\n",
      "Epoch: 02 | Train Loss: 5.941\n",
      "Epoch: 02 | Train Loss: 5.787\n",
      "Epoch: 02 | Train Loss: 5.725\n",
      "Epoch: 02 | Train Loss: 5.776\n",
      "Epoch: 02 | Train Loss: 5.847\n",
      "Epoch: 02 | Train Loss: 5.624\n",
      "Epoch: 02 | Train Loss: 5.720\n",
      "Epoch: 02 | Train Loss: 5.586\n",
      "Epoch: 02 | Train Loss: 5.619\n",
      "Epoch: 02 | Train Loss: 5.459\n",
      "Epoch: 02 | Train Loss: 5.773\n",
      "Epoch: 02 | Train Loss: 6.118\n",
      "Epoch: 02 | Train Loss: 5.756\n",
      "Epoch: 02 | Train Loss: 5.811\n",
      "Epoch: 02 | Train Loss: 5.793\n",
      "Epoch: 02 | Train Loss: 5.945\n",
      "Epoch: 02 | Train Loss: 5.961\n",
      "Epoch: 02 | Train Loss: 5.661\n",
      "Epoch: 02 | Train Loss: 5.984\n",
      "Epoch: 02 | Train Loss: 5.824\n",
      "Epoch: 02 | Train Loss: 5.744\n",
      "Epoch: 02 | Train Loss: 5.731\n",
      "Epoch: 02 | Train Loss: 5.793\n",
      "Epoch: 02 | Train Loss: 5.898\n",
      "Epoch: 02 | Train Loss: 5.824\n",
      "Epoch: 02 | Train Loss: 5.766\n",
      "Epoch: 02 | Train Loss: 5.828\n",
      "Epoch: 02 | Train Loss: 5.931\n",
      "Epoch: 02 | Train Loss: 5.864\n",
      "Epoch: 02 | Train Loss: 5.679\n",
      "Epoch: 02 | Train Loss: 5.957\n",
      "Epoch: 02 | Train Loss: 5.739\n",
      "Epoch: 02 | Train Loss: 5.684\n",
      "Epoch: 02 | Train Loss: 5.655\n",
      "Epoch: 02 | Train Loss: 5.922\n",
      "Epoch: 03 | Train Loss: 5.569\n",
      "Epoch: 03 | Train Loss: 5.639\n",
      "Epoch: 03 | Train Loss: 5.755\n",
      "Epoch: 03 | Train Loss: 5.639\n",
      "Epoch: 03 | Train Loss: 5.566\n",
      "Epoch: 03 | Train Loss: 5.853\n",
      "Epoch: 03 | Train Loss: 5.790\n",
      "Epoch: 03 | Train Loss: 5.637\n",
      "Epoch: 03 | Train Loss: 5.682\n",
      "Epoch: 03 | Train Loss: 5.633\n",
      "Epoch: 03 | Train Loss: 5.695\n",
      "Epoch: 03 | Train Loss: 5.822\n",
      "Epoch: 03 | Train Loss: 5.709\n",
      "Epoch: 03 | Train Loss: 5.777\n",
      "Epoch: 03 | Train Loss: 5.538\n",
      "Epoch: 03 | Train Loss: 5.700\n",
      "Epoch: 03 | Train Loss: 5.581\n",
      "Epoch: 03 | Train Loss: 5.649\n",
      "Epoch: 03 | Train Loss: 5.724\n",
      "Epoch: 03 | Train Loss: 5.641\n",
      "Epoch: 03 | Train Loss: 5.637\n",
      "Epoch: 03 | Train Loss: 5.724\n",
      "Epoch: 03 | Train Loss: 5.606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m----> 3\u001b[0m         loss \u001b[38;5;241m=\u001b[39m train(model, j[\u001b[38;5;241m0\u001b[39m], j[\u001b[38;5;241m1\u001b[39m], optimizer, criterion, CLIP)\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[39], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, src, trg, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m     26\u001b[0m trg \u001b[38;5;241m=\u001b[39m trg[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, trg)\n\u001b[1;32m---> 30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     32\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[0;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    583\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    for i,j in enumerate(train_loader):\n",
    "        loss = train(model, j[0], j[1], optimizer, criterion, CLIP)\n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {loss:.3f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184db10-193d-4235-a53e-84ececb85fe9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for i,j in enumerate(train_loader):\n",
    "    encoderhidden=engenc(j[0])\n",
    "    jptext=j[1]\n",
    "    jptextfirsttok=jptext[:,0]\n",
    "    decodernext,decoderhidden=jpdec(jptextfirsttok,encoderhidden)\n",
    "    print(decodernext.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c830a8b-3550-456f-93f0-c48d1f288e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"LANG TRANSLATION model save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace8566-83ab-4f5f-b24a-bf2b6ac2a789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417bbd2-d538-4622-bf60-f06b8feb4100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e3a50-b00f-4c8c-8487-4c5f0971e343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cae8a9c3-4752-448b-b039-a26f6bdebebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_bert(model, sentence, en_tokenizer, ja_tokenizer, max_len=50, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize and numericalize the input sentence using BERT tokenizer\n",
    "    inputs = en_tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "    input_ids = inputs['input_ids']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden,cellres = model.encoder(input_ids)  # Encoder uses BERT embeddings\n",
    "\n",
    "    trg_index = [ja_tokenizer.cls_token_id]  # Start with [CLS] token for BERT\n",
    "    for _ in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_index[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden,cell = model.decoder(trg_tensor, hidden,cellres)\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_index.append(pred_token)\n",
    "\n",
    "        if pred_token == ja_tokenizer.sep_token_id:  # Stop at [SEP] token\n",
    "            break\n",
    "\n",
    "    # Convert the numerical indices back to Japanese tokens\n",
    "    ja_tokens = ja_tokenizer.convert_ids_to_tokens(trg_index)\n",
    "\n",
    "    # Join the tokens to form the translated sentence (excluding [CLS] and [SEP])\n",
    "    return ja_tokenizer.convert_tokens_to_string(ja_tokens[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "945bf286-2212-4d65-a68b-b4bcef349fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentence = \"Thank you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f62c9ffc-c1a7-4d9f-ba8a-63c27f6baf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_sentence = translate_bert(model, source_sentence, engtokenizer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f0df4e1-997f-44f0-a41f-7adf33ff8507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、 、\n"
     ]
    }
   ],
   "source": [
    "print(translated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cbcc8f-a1cb-4eda-bec7-6223845f1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"Yeah, there is a lot of changes happening lately.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0800ae0-f186-49a1-8efc-8d2ab2c7f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translate_bert(model, sent, engtokenizer, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10765e23-1bd1-4eb7-af03-11f6403e9993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
