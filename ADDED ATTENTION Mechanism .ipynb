{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd548961-cde7-42c2-bd94-218e782501c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertTokenizer\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3052504d-5151-4174-b090-bf1105697b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"test.json\",\"r\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8097871-3421-477b-b6d6-601978105e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9eee845-b27b-4014-be1f-e5a1a7faa805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '190315_E001_13',\n",
       " 'tag': 'meeting',\n",
       " 'title': 'Meeting: Market update meeting',\n",
       " 'original_language': 'en',\n",
       " 'conversation': [{'no': 1,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'How is it going, Wayne?',\n",
       "   'ja_sentence': 'ウェイン、調子はどうです？'},\n",
       "  {'no': 2,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': \"I'm not too bad.\",\n",
       "   'ja_sentence': 'まあまあです。'},\n",
       "  {'no': 3,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Thank you very much for coming out today.',\n",
       "   'ja_sentence': '今日はご足労ありがとう。'},\n",
       "  {'no': 4,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': \"How's business lately?\",\n",
       "   'ja_sentence': '景気はどうです？'},\n",
       "  {'no': 5,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': \"It's been good.\",\n",
       "   'ja_sentence': 'おかげさまで、順調です。'},\n",
       "  {'no': 6,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': \"We recently commissioned a new facility so I've been busy managing that.\",\n",
       "   'ja_sentence': '最近、新しい施設が稼働開始しまして、その管理で忙しくて。'},\n",
       "  {'no': 7,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'I read about that on your company website.',\n",
       "   'ja_sentence': 'ああ、それ、御社のサイトで読みましたよ。'},\n",
       "  {'no': 8,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Congratulations.',\n",
       "   'ja_sentence': 'おめでとうございます。'},\n",
       "  {'no': 9,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Thank you.',\n",
       "   'ja_sentence': 'どうも。'},\n",
       "  {'no': 10,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'The Japanese market has been very interested in our product.',\n",
       "   'ja_sentence': '日本市場が当社製品に興味をもっているようです。'},\n",
       "  {'no': 11,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'So having this new facility should satisfy their demand for the next couple of years.',\n",
       "   'ja_sentence': '新施設のおかげで、今後数年間の需要は賄えるかと思います。'},\n",
       "  {'no': 12,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'The Japanese market is trending upwards lately.',\n",
       "   'ja_sentence': '日本市場は最近上向きだね。'},\n",
       "  {'no': 13,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'I was in Japan last month and talked to a couple of potential customers.',\n",
       "   'ja_sentence': '先月日本に出張して、見込みのありそうな数社とミーティングしてきました。'},\n",
       "  {'no': 14,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'They all told me that they are looking for a reliable and consistent supply.',\n",
       "   'ja_sentence': '全社、声を揃えて、信頼できて一貫性のある供給を望んでいましたね。'},\n",
       "  {'no': 15,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Well, we are well positioned then.',\n",
       "   'ja_sentence': 'では、当社はいい状況にあるってわけですね。'},\n",
       "  {'no': 16,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'We have 6 facilities with over 1 million ton capacity.',\n",
       "   'ja_sentence': '出力百万トン以上の工場が6件ありますし。'},\n",
       "  {'no': 17,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'You also operate your own terminal.',\n",
       "   'ja_sentence': '端末も独自に管理されてますしね。'},\n",
       "  {'no': 18,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Yes, so we can control the ship loading and schedule.',\n",
       "   'ja_sentence': 'そう、出荷量やスケジュールも管理できます。'},\n",
       "  {'no': 19,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Having control over the supply chain is definitely helpful.',\n",
       "   'ja_sentence': 'サプライチェーンを管理できるのはとても助かります。'},\n",
       "  {'no': 20,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Being flexible is really important.',\n",
       "   'ja_sentence': '柔軟性があるのはとても重要です。'},\n",
       "  {'no': 21,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'How has the Korean market been lately?',\n",
       "   'ja_sentence': '韓国市場は最近どんな状況ですか？'},\n",
       "  {'no': 22,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': \"I hear that they aren't looking for long term contracts.\",\n",
       "   'ja_sentence': '長期の契約は望んでいないと聞きましたが。'},\n",
       "  {'no': 23,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Is that true?',\n",
       "   'ja_sentence': 'そうなんでしょうか？'},\n",
       "  {'no': 24,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Yes it is.',\n",
       "   'ja_sentence': '本当みたいです。'},\n",
       "  {'no': 25,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'They are mainly looking for spot contract.',\n",
       "   'ja_sentence': '現物契約中心のようです。'},\n",
       "  {'no': 26,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Why is that?',\n",
       "   'ja_sentence': 'どうしてなんでしょう？'},\n",
       "  {'no': 27,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': \"Well they don't want to overcommit to one supplier.\",\n",
       "   'ja_sentence': 'サプライヤー一社に傾倒したくないんでしょうね。'},\n",
       "  {'no': 28,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'So they prefer to source from various suppliers.',\n",
       "   'ja_sentence': 'なので、いろいろなところから調達したいんですよ。'},\n",
       "  {'no': 29,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Is that to also keep the price down?',\n",
       "   'ja_sentence': '価格を抑える意味もあるんでしょうか？'},\n",
       "  {'no': 30,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'They can compare prices and shop around for the cheapest price.',\n",
       "   'ja_sentence': '価格を比較して、一番安いところから購入するのです。'},\n",
       "  {'no': 31,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Sounds like a lot of work.',\n",
       "   'ja_sentence': 'よっぽど、大変そうですがね。'},\n",
       "  {'no': 32,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'We could offer them a 10-year contract and they can sit back and relax.',\n",
       "   'ja_sentence': '10年契約をオファーすれば、向こうはのんびりリラックスできるのに。'},\n",
       "  {'no': 33,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Yeah, that would make life easier.',\n",
       "   'ja_sentence': 'その方が楽でしょうに。'},\n",
       "  {'no': 34,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'We should keep an eye on that market.',\n",
       "   'ja_sentence': '韓国市場からは目が離せないですね。'},\n",
       "  {'no': 35,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Yeah, there is a lot of changes happening lately.',\n",
       "   'ja_sentence': 'そう、最近、いろいろ変化が起きていますからね。'},\n",
       "  {'no': 36,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'We should catch up again in a couple months?',\n",
       "   'ja_sentence': '２ヶ月後くらいにまた、情報交換しましょう。'},\n",
       "  {'no': 37,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'That would be good.',\n",
       "   'ja_sentence': 'いいですね。'},\n",
       "  {'no': 38,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Great.',\n",
       "   'ja_sentence': '良かった。'},\n",
       "  {'no': 39,\n",
       "   'en_speaker': 'Mr. John Smith',\n",
       "   'ja_speaker': 'ジョン スミスさん',\n",
       "   'en_sentence': 'Thank you for your time today.',\n",
       "   'ja_sentence': '今日はお時間をありがとうございました。'},\n",
       "  {'no': 40,\n",
       "   'en_speaker': 'Mr. Wayne Willis',\n",
       "   'ja_speaker': 'ウェイン ウィリスさん',\n",
       "   'en_sentence': 'Thank you as well.',\n",
       "   'ja_sentence': 'こちらこそ。'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac905ad3-e445-4bba-8b8a-472c76c354c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "english=[]\n",
    "japanese=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd21f0cb-be3c-47c9-9eb0-460b5adef114",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dat in data:\n",
    "    for j in dat['conversation']:\n",
    "        english.append(j['en_sentence'])\n",
    "        japanese.append(j['ja_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50013e7-0cf1-462c-abc6-f16eccc2235c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1e8612-ef7a-4852-8300-1f479e35c64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(japanese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d537196-2d07-48bd-bd2c-9a65e3a049cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_eng=0\n",
    "mx_jp=0\n",
    "for i in range(len(english)):\n",
    "    mx_eng=max(mx_eng,len(english[i]))\n",
    "for i in range(len(japanese)):\n",
    "    mx_jp=max(mx_jp,len(japanese[i]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09703c-0545-4f5a-b1ce-1e0a77f4b9ae",
   "metadata": {},
   "source": [
    "Max of english and Max of Japanese tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61934533-df74-495b-9037-49536ca19c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 95\n"
     ]
    }
   ],
   "source": [
    "print(mx_eng,mx_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44cd-a876-48e0-aa22-b97607712c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a9e297-01b3-422c-aed3-d55a3fd89c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "bertjapanese = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82cfecef-5686-4af6-bd60-7580856cfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    \"bos_token\": \"<sos>\",\n",
    "    \"eos_token\": \"<eos>\",\n",
    "    \"pad_token\": \"<pad>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bbb6e46-f170-4be7-8bfe-be241bd0e8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f012e8fd-06b9-45f7-a232-cab40e3faec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jptokids=[]\n",
    "jptorch=[]\n",
    "for i in range(len(japanese)):\n",
    "    ax = tokenizer.tokenize(japanese[i])\n",
    "    ax = [tokenizer.bos_token] + ax + [tokenizer.eos_token]  \n",
    "    jptokids.append(tokenizer.convert_tokens_to_ids(ax))\n",
    "    jptorch.append(torch.tensor(jptokids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bcdb36-b3c6-4dfb-b9d7-bb612b8594e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fb22e53-41df-4ef0-b7d7-dbb1f59c0c99",
   "metadata": {},
   "source": [
    "This is using tokenizer.encode to automatically add eos and sos \n",
    "\n",
    "for i in range(len(japanese)):\n",
    "    jptokids.append(tokenizer.encode(japanese[i], add_special_tokens=True))  \n",
    "    print(jptokids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fba07688-66ed-4cbe-8e6e-406442b50b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c633c9-41dd-4421-b052-c10bc4288998",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_jp=0\n",
    "vocabsize_jp=0\n",
    "for i in range(len(jptokids)):\n",
    "    maxlen_jp=max(maxlen_jp,len(jptokids[i]))\n",
    "    vocabsize_jp = max(vocabsize_jp,max(jptokids[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f412545b-77cf-490b-974e-270ca3dcc762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 32001)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen_jp,vocabsize_jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3141c88b-b634-4ff8-9658-e725d09479e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engtokenizer=BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5d8a15b-1ffb-44f6-bf9e-9b828c0596e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engtokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1562fb92-99e4-452f-888e-3bcd96083864",
   "metadata": {},
   "outputs": [],
   "source": [
    "engtokids=[]\n",
    "engtorch=[]\n",
    "for i in range(len(english)):\n",
    "    ax=engtokenizer.tokenize(english[i])\n",
    "    ax=[engtokenizer.bos_token]+ax+[engtokenizer.eos_token]\n",
    "    engtokids.append(engtokenizer.convert_tokens_to_ids(ax))\n",
    "    engtorch.append(torch.tensor(engtokids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72bee0a8-d868-4c26-b3c9-e19fcafa76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_eng=0\n",
    "vocabsize_eng=0\n",
    "for i in range(len(engtokids)):\n",
    "    maxlen_eng=max(maxlen_eng,len(engtokids[i]))\n",
    "    vocabsize_eng = max(vocabsize_eng,max(engtokids[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "993addb7-2629-4bd6-a678-bc8b2009308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 30523, 59, 32001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen_eng,vocabsize_eng,maxlen_jp,vocabsize_jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d73fda59-747c-4592-8743-aa05928fad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> ウェイン 、 調子 は どう です ? <eos>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(jptokids[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18b4eb58-0c15-4998-bf7a-d8030eb3a34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how is it going, wayne?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engtokenizer.decode(engtokids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d462bd63-bdb3-4cd9-b6a1-ad0ee9b1fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engpadded= pad_sequence(engtorch, batch_first=True, padding_value=engtokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d8d9227-d8c6-4756-95ee-712e7f0b56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jppadded= pad_sequence(jptorch,batch_first=True ,padding_value=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1de242f9-8acd-4daa-83f8-aadd9ba848df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, en_tensors, jp_tensors):\n",
    "        self.en_tensors = en_tensors\n",
    "        self.jp_tensors = jp_tensors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.en_tensors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return English and Japanese tensors for each sentence pair\n",
    "        return self.en_tensors[idx], self.jp_tensors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ed2b937-b89c-4629-bd11-9e5d2b90bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(en_tensors, jp_tensors, batch_size=32):\n",
    "    dataset = TranslationDataset(en_tensors, jp_tensors)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b641f289-cbec-4d4c-a6d3-af0bcfdc9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_dataloader(engpadded, jppadded, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d5d3c0-fc2c-4164-8452-99e6bfa3ca12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0ca2579-16ec-495a-8c03-8490debb0668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30522,  2044,  2035,  ..., 30524, 30524, 30524],\n",
      "        [30522,  2011,  4566,  ..., 30524, 30524, 30524],\n",
      "        [30522,  2079,  2017,  ..., 30524, 30524, 30524],\n",
      "        ...,\n",
      "        [30522,  2057,  1005,  ..., 30524, 30524, 30524],\n",
      "        [30522,  2064,  2017,  ..., 30524, 30524, 30524],\n",
      "        [30522,  2469,  1010,  ..., 30524, 30524, 30524]])\n",
      "tensor([[32000,  5408, 30054,  ..., 32002, 32002, 32002],\n",
      "        [32000,  2015, 29633,  ..., 32002, 32002, 32002],\n",
      "        [32000,   654,     5,  ..., 32002, 32002, 32002],\n",
      "        ...,\n",
      "        [32000,  2941,  1974,  ..., 32002, 32002, 32002],\n",
      "        [32000, 18659,     7,  ..., 32002, 32002, 32002],\n",
      "        [32000,  8871,     6,  ..., 32002, 32002, 32002]])\n"
     ]
    }
   ],
   "source": [
    "for i in next(iter(train_loader)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "120b1adc-2626-455f-8a91-63ccf7ff4b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45])\n",
      "torch.Size([59])\n"
     ]
    }
   ],
   "source": [
    "for i in next(iter(train_loader)):\n",
    "    print(i[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e06aaf3-0d42-4c0b-aa48-e4c4d719616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eencoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hid_dim * 2, hid_dim) # For combining bidirectional outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8defb313-c78a-4b0d-86e8-cad1f80dac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hid_dim * 3, hid_dim)\n",
    "        self.v = nn.Linear(hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return nn.functional.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "449c7fae-58ba-48df-b287-ce86237d5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deecoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e63d335c-4a47-4633-b7dd-4ab5ef0e9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        input = trg[:, 0]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c8a739d-aedb-4820-9470-c0687a89e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "engenc=eencoder(input_dim=31000,emb_dim=30,hid_dim=800,dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe17323e-9f4c-44c6-96d9-2e073e23f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "att=Attention(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e3205a4-fe60-4e75-a19f-976b852c2362",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpdec=deecoder(output_dim=32100,emb_dim=30,hid_dim=800,dropout=0.2,attention=att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "684f944b-2154-446e-b2a5-fe1524ee39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(engenc, jpdec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7053885-3c13-4578-b041-d36bb66c02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a7b97e6-be5e-4626-bbd3-94db22b1274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, src, trg, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(src, trg)\n",
    "    output_dim = output.shape[-1]\n",
    "    output = output[:, 1:].reshape(-1, output_dim)\n",
    "    trg = trg[:, 1:].reshape(-1)\n",
    "    loss = criterion(output, trg)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "CLIP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed6d3dbd-8d24-4c71-b40c-d8af4b8f6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e544567e-468d-452a-bd75-52b7ee81aafc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 830, got 1630",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m----> 3\u001b[0m         loss \u001b[38;5;241m=\u001b[39m train(model, j[\u001b[38;5;241m0\u001b[39m], j[\u001b[38;5;241m1\u001b[39m], optimizer, criterion, CLIP)\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[53], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, src, trg, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 4\u001b[0m output \u001b[38;5;241m=\u001b[39m model(src, trg)\n\u001b[0;32m      5\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      6\u001b[0m output \u001b[38;5;241m=\u001b[39m output[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output_dim)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[47], line 16\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[1;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m trg[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, trg_len):\n\u001b[1;32m---> 16\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\u001b[38;5;28minput\u001b[39m, hidden, encoder_outputs)\n\u001b[0;32m     17\u001b[0m     outputs[:, t] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m     18\u001b[0m     teacher_force \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m teacher_forcing_ratio\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[46], line 18\u001b[0m, in \u001b[0;36mdeecoder.forward\u001b[1;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[0;32m     16\u001b[0m weighted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(a, encoder_outputs)\n\u001b[0;32m     17\u001b[0m rnn_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((embedded, weighted), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(rnn_input, hidden\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     19\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction, hidden\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1390\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1386\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m   1387\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m-> 1390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1392\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[0;32m   1393\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1394\u001b[0m         hx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1401\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[0;32m   1402\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:361\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]\n\u001b[0;32m    360\u001b[0m ):\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m    362\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:312\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    310\u001b[0m     )\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 830, got 1630"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    for i,j in enumerate(train_loader):\n",
    "        loss = train(model, j[0], j[1], optimizer, criterion, CLIP)\n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {loss:.3f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184db10-193d-4235-a53e-84ececb85fe9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for i,j in enumerate(train_loader):\n",
    "    encoderhidden=engenc(j[0])\n",
    "    jptext=j[1]\n",
    "    jptextfirsttok=jptext[:,0]\n",
    "    decodernext,decoderhidden=jpdec(jptextfirsttok,encoderhidden)\n",
    "    print(decodernext.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c830a8b-3550-456f-93f0-c48d1f288e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"LANG TRANSLATION model save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace8566-83ab-4f5f-b24a-bf2b6ac2a789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417bbd2-d538-4622-bf60-f06b8feb4100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e3a50-b00f-4c8c-8487-4c5f0971e343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8a9c3-4752-448b-b039-a26f6bdebebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_bert(model, sentence, en_tokenizer, ja_tokenizer, max_len=50, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize and numericalize the input sentence using BERT tokenizer\n",
    "    inputs = en_tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "    input_ids = inputs['input_ids']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(input_ids)  # Encoder uses BERT embeddings\n",
    "\n",
    "    trg_index = [ja_tokenizer.cls_token_id]  # Start with [CLS] token for BERT\n",
    "    for _ in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_index[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden)\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_index.append(pred_token)\n",
    "\n",
    "        if pred_token == ja_tokenizer.sep_token_id:  # Stop at [SEP] token\n",
    "            break\n",
    "\n",
    "    # Convert the numerical indices back to Japanese tokens\n",
    "    ja_tokens = ja_tokenizer.convert_ids_to_tokens(trg_index)\n",
    "\n",
    "    # Join the tokens to form the translated sentence (excluding [CLS] and [SEP])\n",
    "    return ja_tokenizer.convert_tokens_to_string(ja_tokens[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945bf286-2212-4d65-a68b-b4bcef349fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentence = \"Thank you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c9ffc-c1a7-4d9f-ba8a-63c27f6baf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_sentence = translate_bert(model, source_sentence, engtokenizer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0df4e1-997f-44f0-a41f-7adf33ff8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cbcc8f-a1cb-4eda-bec7-6223845f1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"Yeah, there is a lot of changes happening lately.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0800ae0-f186-49a1-8efc-8d2ab2c7f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translate_bert(model, sent, engtokenizer, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10765e23-1bd1-4eb7-af03-11f6403e9993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
